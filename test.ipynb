{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "cross-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2\n",
    "num = 1\n",
    "intere_num =4\n",
    "indices_top = torch.randint(0,5,(batch,num))\n",
    "indicex_K = torch.randint(0,5,(batch,intere_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "assisted-antigua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1]]), tensor([[2, 0, 3, 1],\n",
       "         [3, 4, 4, 4]]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_top,indicex_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "detected-coaching",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicex_K.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "european-rescue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = indices_top.unsqueeze(-1).repeat(1,1,1,intere_num).reshape(batch,-1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "educational-taiwan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 0, 3, 1],\n",
       "        [3, 4, 4, 4]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = indicex_K.repeat(1,1,num).reshape(batch,-1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "peaceful-particular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([0, 0, 0, 0]), tensor([2, 0, 3, 1])],\n",
       " [tensor([1, 1, 1, 1]), tensor([3, 4, 4, 4])]]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinate = [[a,b] for a,b in zip(x, y)]\n",
    "coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "narrow-documentation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0038, 0.3236, 0.3759, 0.8879, 0.3769],\n",
       "        [0.6577, 0.1867, 0.5111, 0.2980, 0.2138],\n",
       "        [0.0371, 0.0204, 0.9866, 0.8967, 0.3042],\n",
       "        [0.7230, 0.5741, 0.8102, 0.5139, 0.4177],\n",
       "        [0.5401, 0.5997, 0.4795, 0.1747, 0.4590]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_matrix = torch.rand(5,5)\n",
    "state_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "crude-constitutional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1.5912]), tensor([0.9395])]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[state_matrix[co].reshape(num,-1).sum(dim=-1) for co in coordinate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "finnish-grain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5912],\n",
       "        [0.9395]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([state_matrix[co].reshape(num,-1).sum(dim=-1) for co in coordinate]).reshape(batch,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "destroyed-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "thermal-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_K = torch.tensor([[1,2,3],[4,5,6]])\n",
    "hitted_idx = torch.tensor([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "diagnostic-census",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 6],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_K[hitted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "stone-parade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([indices_K[a,b] for a,b in enumerate(hitted_idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "expensive-satisfaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 6])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_K[[0,1],[1,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "discrete-transmission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 1],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitted_idx = hitted_idx.reshape(-1,1).repeat(1,3)\n",
    "hitted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aware-processor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 1, 1, 1, 4, 5, 6, 1, 1, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.cat([a,b]) for a,b in zip(indices_K, hitted_idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "actual-upper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [1, 1, 1]],\n",
       "\n",
       "        [[4, 5, 6],\n",
       "         [1, 1, 1]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinate = torch.cat([torch.cat([a,b]).reshape(2,-1) for a,b in zip(indices_K, hitted_idx)]).reshape(-1,2,3)\n",
    "coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "reflected-croatia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8992, 0.2708, 0.9456, 0.4589, 0.2460, 0.4221, 0.0032, 0.1878, 0.8658,\n",
       "         0.1525],\n",
       "        [0.5863, 0.5381, 0.4096, 0.6247, 0.5890, 0.5427, 0.9217, 0.2185, 0.2247,\n",
       "         0.5942],\n",
       "        [0.9760, 0.1699, 0.7436, 0.7046, 0.2264, 0.9429, 0.8133, 0.7484, 0.8475,\n",
       "         0.8991],\n",
       "        [0.6667, 0.0898, 0.3281, 0.9240, 0.2775, 0.7245, 0.1304, 0.9007, 0.0738,\n",
       "         0.9207],\n",
       "        [0.2720, 0.9936, 0.6298, 0.7130, 0.2564, 0.6909, 0.8498, 0.5069, 0.7609,\n",
       "         0.4941],\n",
       "        [0.2214, 0.7662, 0.4298, 0.2983, 0.9334, 0.8935, 0.9072, 0.8236, 0.4182,\n",
       "         0.8915],\n",
       "        [0.4789, 0.6074, 0.1716, 0.9682, 0.5670, 0.7137, 0.1155, 0.5780, 0.4163,\n",
       "         0.1845],\n",
       "        [0.6600, 0.7084, 0.0840, 0.4456, 0.3727, 0.0399, 0.7062, 0.0883, 0.1861,\n",
       "         0.6693],\n",
       "        [0.8065, 0.0205, 0.1175, 0.6070, 0.6301, 0.0767, 0.6143, 0.0519, 0.5735,\n",
       "         0.7901],\n",
       "        [0.8914, 0.5336, 0.7749, 0.5669, 0.9348, 0.8793, 0.5937, 0.9090, 0.0525,\n",
       "         0.8439]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = torch.rand([10,10])\n",
    "crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cross-transport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5381, 0.1699, 0.0898])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf[coordinate[0].numpy().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "pretty-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinate = coordinate.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "built-bibliography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5381, 0.1699, 0.0898],\n",
       "        [0.9936, 0.7662, 0.6074]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([crf[co] for co in coordinate]).reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "involved-stick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7978, 2.3671])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([crf[co] for co in coordinate]).reshape(-1,3).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-chassis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "statutory-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Data_Read\n",
    "from Config import Config\n",
    "config = Config()\n",
    "config.datasetInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "attached-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lists, test_x, test_y = Data_Read(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compound-douglas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25909, 38756, 44804, 54540, 56212, 39989],\n",
       "       [56212, 38756,  2890, 44804, 47381, 54540],\n",
       "       [47381, 25909,  2890, 44804, 54540, 56212],\n",
       "       ...,\n",
       "       [32544, 41386, 18642, 60271, 18701, 37261],\n",
       "       [60476, 37225, 47386, 13732, 46591,  1391],\n",
       "       [25794, 60468, 33344, 34858, 13382, 42266]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lists[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "foreign-juice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38756, 47381, 25909, 54540,  2890, 44804, 56212])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = train_lists[2][2]\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "related-court",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = [x for x in range(6)]\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "chinese-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "humanitarian-breach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 \n",
      "2 1 \n",
      "2 0 \n",
      "3 2 \n",
      "3 1 \n",
      "3 0 \n",
      "4 3 \n",
      "4 2 \n",
      "4 1 \n",
      "4 0 \n",
      "5 4 \n",
      "5 3 \n",
      "5 2 \n",
      "5 1 \n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(seq):\n",
    "    if i>0:\n",
    "        l = min(i,window)\n",
    "        for j in range(l):\n",
    "            print(\"{} {} \".format(item,seq[i-1-j]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "collected-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "agreed-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_layer = nn.Embedding(4,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "israeli-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = embed_layer(torch.tensor(1))\n",
    "e2 = embed_layer(torch.tensor(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "variable-garage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0404,  1.0936, -1.1947, -0.0090,  0.9085,  0.6575, -0.4485,  1.6211,\n",
       "         -1.2566, -0.1157], grad_fn=<EmbeddingBackward>),\n",
       " tensor([-0.9740,  0.2802,  0.3881,  1.9925,  0.3055, -1.8050, -0.0507,  0.7508,\n",
       "          0.9224,  0.2238], grad_fn=<EmbeddingBackward>))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1,e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "opposite-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "e1=torch.tensor([2,3,4,5])\n",
    "e2=torch.tensor([1,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "generic-newton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"i,i\",e1,e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "broadband-alias",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "lovely-excellence",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_bias = nn.Parameter(torch.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "wanted-distance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2929, -0.6695,  1.0150, -0.1858, -0.1017,  0.0922,  1.7807,  0.0423,\n",
       "        -0.2277, -2.7700], requires_grad=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "extensive-dakota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2929, -0.6695,  1.0150, -0.1858, -0.1017,  0.0922,  1.7807,  0.0423,\n",
       "         -0.2277, -2.7700],\n",
       "        [ 0.2929, -0.6695,  1.0150, -0.1858, -0.1017,  0.0922,  1.7807,  0.0423,\n",
       "         -0.2277, -2.7700],\n",
       "        [ 0.2929, -0.6695,  1.0150, -0.1858, -0.1017,  0.0922,  1.7807,  0.0423,\n",
       "         -0.2277, -2.7700],\n",
       "        [ 0.2929, -0.6695,  1.0150, -0.1858, -0.1017,  0.0922,  1.7807,  0.0423,\n",
       "         -0.2277, -2.7700],\n",
       "        [ 0.2929, -0.6695,  1.0150, -0.1858, -0.1017,  0.0922,  1.7807,  0.0423,\n",
       "         -0.2277, -2.7700]], grad_fn=<RepeatBackward>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_bias.repeat(5,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "refined-karaoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2929,  0.2929,  0.2929,  0.2929,  0.2929],\n",
       "        [-0.6695, -0.6695, -0.6695, -0.6695, -0.6695],\n",
       "        [ 1.0150,  1.0150,  1.0150,  1.0150,  1.0150],\n",
       "        [-0.1858, -0.1858, -0.1858, -0.1858, -0.1858],\n",
       "        [-0.1017, -0.1017, -0.1017, -0.1017, -0.1017],\n",
       "        [ 0.0922,  0.0922,  0.0922,  0.0922,  0.0922],\n",
       "        [ 1.7807,  1.7807,  1.7807,  1.7807,  1.7807],\n",
       "        [ 0.0423,  0.0423,  0.0423,  0.0423,  0.0423],\n",
       "        [-0.2277, -0.2277, -0.2277, -0.2277, -0.2277],\n",
       "        [-2.7700, -2.7700, -2.7700, -2.7700, -2.7700]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_bias.repeat(5,1).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-horse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "proud-dialogue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embed_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "martial-botswana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(co_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "assisted-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "emotional-meter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67133267, 0.70346716, 0.54755072, 0.60374291],\n",
       "       [0.12035645, 0.4792099 , 0.06570049, 0.91839773],\n",
       "       [0.37675805, 0.46255179, 0.68269883, 0.43839234],\n",
       "       [0.12081551, 0.15161369, 0.97321902, 0.8758381 ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matr = np.random.rand(4,4)\n",
    "m = 0.5\n",
    "matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "virtual-marshall",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-5ae58bef058d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "min(1.0, matr/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "governing-floating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.34266534, 1.40693432, 1.09510145, 1.20748582],\n",
       "        [0.2407129 , 0.9584198 , 0.13140099, 1.83679546],\n",
       "        [0.75351611, 0.92510359, 1.36539767, 0.87678468],\n",
       "        [0.24163101, 0.30322739, 1.94643803, 1.75167621]]),\n",
       " array([[1.        , 1.        , 1.        , 1.        ],\n",
       "        [0.2407129 , 0.9584198 , 0.13140099, 1.        ],\n",
       "        [0.75351611, 0.92510359, 1.        , 0.87678468],\n",
       "        [0.24163101, 0.30322739, 1.        , 1.        ]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(matr/m),np.clip((matr/m),a_min=0, a_max=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fabulous-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "np1 = np.array([[1,1],[1,0]])\n",
    "np2 = np.array([[1,2],[3,4]])\n",
    "ten1 = torch.tensor([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "wound-silver",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'numpy.ndarray' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-0d49858841e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mten1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'numpy.ndarray' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "np1+ten1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "vanilla-restoration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(min(torch.tensor(1.0), 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "forced-growing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4],\n",
       "        [ 9, 16]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten1.pow(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-northeast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-complement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fuzzy-chain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3],\n",
       "        [2, 3, 4],\n",
       "        [5, 3, 1]]), Parameter containing:\n",
       " tensor([-0.8213, -0.7490,  0.4412], requires_grad=True))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_matrix = np.array([[1,2,3],[2,3,4],[5,3,1]])\n",
    "co_bias = nn.Parameter(torch.randn(3)) \n",
    "co_matrix,co_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "laughing-particular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3796, -1.7199,  1.4499, -0.0999, -0.0561],\n",
       "        [ 1.0369,  0.9192, -0.2725, -0.5627,  1.7717],\n",
       "        [-0.9230, -0.5910,  0.0739, -0.7949,  0.1797]], requires_grad=True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embed = nn.Embedding(3,5)\n",
    "item_embed.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "lesbian-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_sim = torch.einsum(\"ik,jk -> ij\",item_embed.weight,item_embed.weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "passing-semester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.2176, -1.6257,  0.8425],\n",
       "        [-1.6257,  5.4499, -0.7547],\n",
       "        [ 0.8425, -0.7547,  1.8708]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "champion-wyoming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6427, -1.5703, -0.3801],\n",
       "        [-1.5703, -1.4980, -0.3078],\n",
       "        [-0.3801, -0.3078,  0.8824]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias  = co_bias.repeat(3,1) + co_bias.repeat(3,1).transpose(0,1)\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "reported-composition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 1. , 1. ],\n",
       "       [1. , 1. , 1. ],\n",
       "       [1. , 1. , 0.5]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = np.clip(co_matrix/2,a_min=0, a_max=1.0)\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "adolescent-toronto",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3151, 26.9983,  6.4393],\n",
       "        [26.9983,  0.9063, 25.6289],\n",
       "        [20.5896, 16.5039,  1.5369]], dtype=torch.float64,\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.tensor(weight) * ((embed_sim + bias - torch.tensor(co_matrix)).pow(2))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "million-tract",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128.9166, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "historical-photography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.8"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-vinyl",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
